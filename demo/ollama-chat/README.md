# demo/ollama-chat

æœ€ç®€å•çš„ ICEE æœ¬åœ° AI æ¼”ç¤ºï¼šæŠŠç”¨æˆ·é—®é¢˜å‘ç»™æœ¬åœ° Ollamaï¼Œè¿”å› AI å›ç­”ã€‚

```
Input â†’ LLM(ollama/llama3.2) â†’ Output
```

---

## å‰ç½®è¦æ±‚

### 1. å®‰è£… Ollama

å‰å¾€ https://ollama.com ä¸‹è½½å¹¶å®‰è£… Ollamaï¼Œç„¶åæ‹‰å–æ¨¡å‹ï¼š

```bash
# æ¨èå…¥é—¨æ¨¡å‹ (çº¦ 2GB)
ollama pull llama3.2

# ä¸­æ–‡æ•ˆæœæ›´å¥½çš„æ›¿ä»£é€‰é¡¹
ollama pull qwen2.5:3b

# ç¡®è®¤ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œ
ollama serve
```

### 2. ç¡®è®¤ Node.js ç‰ˆæœ¬ â‰¥ 24

```bash
node --version   # å¿…é¡» v24.x æˆ–æ›´é«˜ï¼ˆnode:sqlite å†…ç½®æ¨¡å—ä¾èµ–ï¼‰
```

---

## è¿è¡Œ

åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œï¼š

```bash
# æ–¹å¼ä¸€ï¼štsx ç›´æ¥è¿è¡Œï¼ˆå¼€å‘æ¨¡å¼ï¼Œæ— éœ€ç¼–è¯‘ï¼‰
pnpm --filter @icee/cli run dev -- run demo/ollama-chat/graph.json \
  --input '{"query": "ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯ AI Agent"}'

# æ–¹å¼äºŒï¼šæŒ‡å®šä¸­æ–‡é—®é¢˜
pnpm --filter @icee/cli run dev -- run demo/ollama-chat/graph.json \
  --input '{"query": "What is the meaning of life?"}'

# æ–¹å¼ä¸‰ï¼šè‡ªå®šä¹‰ Ollama åœ°å€ï¼ˆå¦‚æœä¸åœ¨é»˜è®¤ç«¯å£ï¼‰
pnpm --filter @icee/cli run dev -- run demo/ollama-chat/graph.json \
  --input '{"query": "ä½ å¥½"}' \
  --ollama-url http://localhost:11434

# æ–¹å¼å››ï¼šå¼ºåˆ¶ mock æ¨¡å¼ï¼ˆæ— éœ€ Ollamaï¼Œæµ‹è¯•ç”¨ï¼‰
pnpm --filter @icee/cli run dev -- run demo/ollama-chat/graph.json \
  --input '{"query": "hello"}' \
  --mock
```

### ä½¿ç”¨ä¸åŒæ¨¡å‹

ä¿®æ”¹ `graph.json` é‡Œ `chat` èŠ‚ç‚¹çš„ `model` å­—æ®µï¼š

```json
"config": {
  "provider": "ollama",
  "model": "qwen2.5:3b",   // æ”¹è¿™é‡Œ
  ...
}
```

æˆ–è€…å¤åˆ¶ `graph.json` ä¸ºæ–°æ–‡ä»¶å†ä¿®æ”¹ã€‚

---

## æœŸæœ›è¾“å‡ºç¤ºä¾‹

```
[ICEE] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[ICEE] ICEE Agent Graph Runtime v0.1
[ICEE] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[ICEE] Loading graph: demo/ollama-chat/graph.json
[ICEE] Graph: "Ollama Chat" (3 nodes, 2 edges)
[ICEE] Checking Ollama at http://localhost:11434...
[ICEE] âœ… Ollama is available. Models: llama3.2:latest
[ICEE] Database: /path/to/icee.db
[ICEE] â–¶ Run started: run_abc123
[ICEE]   â†’ [INPUT] User Query
[ICEE]   âœ“ input completed
[ICEE]   â†’ [LLM] Ollama LLM
[ICEE]   ğŸ¤– LLM call â†’ ollama/llama3.2
[ICEE]      Prompt (29 chars)
[ICEE]      âœ“ 84 tokens
[ICEE]      Output: AI Agent æ˜¯ä¸€ç§èƒ½å¤Ÿè‡ªä¸»æ„ŸçŸ¥ç¯å¢ƒã€åšå‡ºå†³ç­–å¹¶æ‰§è¡Œè¡ŒåŠ¨çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿâ€¦
[ICEE]   âœ“ chat completed
[ICEE]   â†’ [OUTPUT] Response
[ICEE]   âœ“ output completed
[ICEE] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[ICEE] âœ… Run COMPLETED
[ICEE]    Duration: 3421ms
[ICEE]    Tokens:   84
[ICEE]    Cost:     $0.000000
[ICEE] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[ICEE] Total wall time: 3650ms
```

---

## æŸ¥çœ‹å†å² Run

æ‰€æœ‰ run éƒ½æŒä¹…åŒ–åˆ° SQLiteï¼Œå¯ä»¥ç”¨ list å‘½ä»¤æŸ¥çœ‹ï¼š

```bash
pnpm --filter @icee/cli run dev -- list
```

---

## å¦‚æœ Ollama ä¸å¯è¾¾

CLI ä¼šè‡ªåŠ¨é™çº§ä¸º mock æ¨¡å¼å¹¶æ‰“å°è­¦å‘Šï¼š

```
[ICEE] âš ï¸  Ollama not reachable at http://localhost:11434
[ICEE] âš ï¸  Falling back to mock mode. Start Ollama and rerun to use real AI.
[ICEE] âš ï¸  Hint: ollama serve  /  ollama pull llama3.2
```
