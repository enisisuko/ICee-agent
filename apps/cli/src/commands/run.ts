import fs from "fs";
import path from "path";
import { GraphDefinitionSchema } from "@icee/shared";
import { getDatabase, RunRepository, StepRepository, EventRepository } from "@icee/db";
import {
  GraphRuntime, GraphNodeRunner, NodeExecutorRegistry,
  InputNodeExecutor, OutputNodeExecutor, LLMNodeExecutor,
  ToolNodeExecutor, MemoryNodeExecutor, ReflectionNodeExecutor, PlanningNodeExecutor
} from "@icee/core";
import { OllamaProvider } from "@icee/providers";

/** run å‘½ä»¤é€‰é¡¹ç±»å‹ */
interface RunOptions {
  input?: string;
  db: string;
  maxTokens?: number;
  maxCost?: number;
  /** Ollama æœåŠ¡åœ°å€ï¼Œé»˜è®¤ http://localhost:11434 */
  ollamaUrl?: string;
  /** å¼ºåˆ¶ä½¿ç”¨ mock æ¨¡å¼ï¼ˆä¸è¿æ¥çœŸå® Ollamaï¼Œé€‚åˆæµ‹è¯•ï¼‰ */
  mock?: boolean;
}

/**
 * icee run <graphFile> å‘½ä»¤å®ç°
 *
 * é»˜è®¤è¡Œä¸ºï¼š
 *   - æ£€æŸ¥ Ollama æ˜¯å¦å¯ç”¨ï¼Œå¯ç”¨åˆ™æ¥å…¥çœŸå® LLM
 *   - Ollama ä¸å¯ç”¨æ—¶æ‰“å°è­¦å‘Šå¹¶è‡ªåŠ¨é™çº§ä¸º mock æ¨¡å¼
 *   - ä¼ å…¥ --mock å¼ºåˆ¶ä½¿ç”¨ mockï¼Œè·³è¿‡å¥åº·æ£€æŸ¥
 *
 * LLM provider ä¼˜å…ˆçº§:
 *   1. --mock flag â†’ mock
 *   2. Ollama å¥åº·æ£€æŸ¥é€šè¿‡ â†’ çœŸå® OllamaProvider
 *   3. Ollama ä¸å¯è¾¾ â†’ é™çº§ mockï¼ˆé™„è­¦å‘Šï¼‰
 */
export async function runCommand(
  graphFile: string,
  opts: RunOptions
): Promise<void> {
  const ollamaBaseUrl = opts.ollamaUrl ?? "http://localhost:11434";

  console.log(`[ICEE] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
  console.log(`[ICEE] ICEE Agent Graph Runtime v0.1`);
  console.log(`[ICEE] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
  console.log(`[ICEE] Loading graph: ${graphFile}`);

  // â”€â”€ è§£æ graph æ–‡ä»¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const absolutePath = path.resolve(graphFile);
  if (!fs.existsSync(absolutePath)) {
    console.error(`[ICEE] âŒ Graph file not found: ${absolutePath}`);
    process.exit(1);
  }

  let graphRaw: unknown;
  try {
    graphRaw = JSON.parse(fs.readFileSync(absolutePath, "utf-8"));
  } catch (e) {
    console.error(`[ICEE] âŒ Failed to parse graph JSON: ${(e as Error).message}`);
    process.exit(1);
  }

  const graphResult = GraphDefinitionSchema.safeParse(graphRaw);
  if (!graphResult.success) {
    console.error("[ICEE] âŒ Invalid graph definition:");
    console.error(JSON.stringify(graphResult.error.format(), null, 2));
    process.exit(1);
  }
  const graph = graphResult.data;
  console.log(`[ICEE] Graph: "${graph.name}" (${graph.nodes.length} nodes, ${graph.edges.length} edges)`);

  // â”€â”€ è§£æè¾“å…¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  let input: Record<string, unknown> | undefined;
  if (opts.input) {
    try {
      input = JSON.parse(opts.input) as Record<string, unknown>;
    } catch {
      console.error(`[ICEE] âŒ --input must be valid JSON. Got: ${opts.input}`);
      process.exit(1);
    }
  }

  // â”€â”€ ç¡®å®š LLM Provider æ¨¡å¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  let useMock = opts.mock === true;
  let ollamaProvider: OllamaProvider | null = null;

  if (!useMock) {
    // å°è¯• Ollama å¥åº·æ£€æŸ¥
    console.log(`[ICEE] Checking Ollama at ${ollamaBaseUrl}...`);
    const tempProvider = new OllamaProvider({ baseUrl: ollamaBaseUrl });
    const isHealthy = await tempProvider.healthCheck();

    if (isHealthy) {
      ollamaProvider = tempProvider;
      const models = await tempProvider.listModels();
      console.log(`[ICEE] âœ… Ollama is available. Models: ${models.slice(0, 5).join(", ") || "(none pulled)"}`);
    } else {
      useMock = true;
      console.warn(`[ICEE] âš ï¸  Ollama not reachable at ${ollamaBaseUrl}`);
      console.warn(`[ICEE] âš ï¸  Falling back to mock mode. Start Ollama and rerun to use real AI.`);
      console.warn(`[ICEE] âš ï¸  Hint: ollama serve  /  ollama pull llama3.2`);
    }
  } else {
    console.log(`[ICEE] Mock mode enabled (--mock flag)`);
  }

  // â”€â”€ åˆå§‹åŒ–æ•°æ®åº“ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const iceeDb = getDatabase(opts.db);
  const runRepo = new RunRepository(iceeDb.instance);
  const stepRepo = new StepRepository(iceeDb.instance);
  const eventRepo = new EventRepository(iceeDb.instance);
  console.log(`[ICEE] Database: ${path.resolve(opts.db)}`);

  // â”€â”€ æ³¨å†ŒèŠ‚ç‚¹æ‰§è¡Œå™¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const registry = new NodeExecutorRegistry();
  registry.register(new InputNodeExecutor());
  registry.register(new OutputNodeExecutor());
  registry.register(new MemoryNodeExecutor());

  // LLM æ‰§è¡Œå™¨ â€” çœŸå® Ollama æˆ– mock
  if (ollamaProvider) {
    const provider = ollamaProvider;
    registry.register(new LLMNodeExecutor(async (config, _input) => {
      const modelLabel = `${config.provider ?? "ollama"}/${config.model}`;
      console.log(`[ICEE]   ğŸ¤– LLM call â†’ ${modelLabel}`);
      console.log(`[ICEE]      Prompt (${(config.promptTemplate ?? "").length} chars)`);

      try {
        const requestPayload: import("@icee/shared").LLMRequest = {
          model: config.model,
          messages: [
            {
              role: "system",
              content: config.systemPrompt ?? "You are a helpful assistant.",
            },
            {
              role: "user",
              // promptTemplate å·²ç»ç”± LLMNodeExecutor æ¸²æŸ“å¥½äº†å ä½ç¬¦
              content: config.promptTemplate ?? "",
            },
          ],
          stream: true,
          // exactOptionalPropertyTypes: åªæœ‰æœ‰å€¼æ—¶æ‰è®¾ç½®
          ...(config.temperature !== undefined && { temperature: config.temperature }),
          ...(config.topP !== undefined && { topP: config.topP }),
          ...(config.maxTokens !== undefined && { maxTokens: config.maxTokens }),
        };
        const result = await provider.generateComplete(requestPayload);

        console.log(`[ICEE]      âœ“ ${result.tokens} tokens`);
        // æˆªæ–­æ˜¾ç¤ºå‰ 200 å­—ç¬¦
        const preview = result.text.slice(0, 200).replace(/\n/g, " ");
        console.log(`[ICEE]      Output: ${preview}${result.text.length > 200 ? "â€¦" : ""}`);
        return result;
      } catch (e) {
        const msg = (e as Error).message;
        console.error(`[ICEE]   âŒ Ollama error: ${msg}`);
        // å¦‚æœæ˜¯æ¨¡å‹æœªæ‰¾åˆ°ï¼Œç»™å‡ºå‹å¥½æç¤º
        if (msg.includes("model") || msg.includes("404")) {
          console.error(`[ICEE]   ğŸ’¡ Hint: run  ollama pull ${config.model}  to download the model`);
        }
        throw e;
      }
    }));
  } else {
    // Mock LLM æ‰§è¡Œå™¨
    registry.register(new LLMNodeExecutor(async (config, _input) => {
      const modelLabel = `${config.provider ?? "mock"}/${config.model}`;
      console.log(`[ICEE]   ğŸ”² LLM mock â†’ ${modelLabel}`);
      return {
        text: `[Mock LLM output for model ${config.model}] â€” Start Ollama to get real AI responses.`,
        tokens: 100,
        costUsd: 0,
        providerMeta: { provider: "mock", model: config.model },
      };
    }));
  }

  // Tool æ‰§è¡Œå™¨ (mock â€” å·¥å…·ç³»ç»Ÿå°†åœ¨åç»­ç‰ˆæœ¬æ¥å…¥)
  registry.register(new ToolNodeExecutor(async (toolName, _version, toolInput, _timeout) => {
    console.log(`[ICEE]   ğŸ”§ Tool: ${toolName}`, JSON.stringify(toolInput).slice(0, 100));
    return { result: `[Mock tool output from ${toolName}]` };
  }));

  // Planning æ‰§è¡Œå™¨ (mock)
  registry.register(new PlanningNodeExecutor(async (goal, _mode) => {
    return {
      tasks: [{ id: "task-1", description: String(goal), priority: 1 }],
      totalSteps: 1,
      strategy: "sequential" as const,
    };
  }));

  // Reflection æ‰§è¡Œå™¨ (mock)
  registry.register(new ReflectionNodeExecutor(async (reflInput, threshold) => ({
    shouldRetry: false,
    confidence: (threshold ?? 0.6) + 0.1,
    reasoning: "Output quality is acceptable",
    modifiedOutput: reflInput,
  })));

  const nodeRunner = new GraphNodeRunner(registry);

  // â”€â”€ å¯åŠ¨ Runtime â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const startTime = Date.now();

  const runtime = new GraphRuntime(
    nodeRunner,
    runRepo,
    stepRepo,
    eventRepo,
    (event) => {
      switch (event.type) {
        case "event:run_started":
          console.log(`[ICEE] â–¶ Run started: ${event.payload.runId}`);
          break;
        case "event:step_started":
          console.log(`[ICEE]   â†’ [${event.payload.nodeType}] ${event.payload.nodeLabel}`);
          break;
        case "event:step_completed":
          console.log(`[ICEE]   âœ“ ${event.payload.nodeId} completed`);
          break;
        case "event:run_completed":
          console.log(`[ICEE] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
          console.log(`[ICEE] âœ… Run ${event.payload.state}`);
          console.log(`[ICEE]    Duration: ${event.payload.durationMs}ms`);
          console.log(`[ICEE]    Tokens:   ${event.payload.totalTokens}`);
          console.log(`[ICEE]    Cost:     $${event.payload.totalCostUsd.toFixed(6)}`);
          if (event.payload.output) {
            console.log(`[ICEE]    Output:`);
            console.log(JSON.stringify(event.payload.output, null, 2));
          }
          console.log(`[ICEE] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
          break;
        case "event:error":
          console.error(`[ICEE] âŒ Error: ${event.payload.error.message}`);
          break;
      }
    }
  );

  let runId: string;
  try {
    runId = await runtime.startRun(graph, input);
  } catch (e) {
    console.error(`[ICEE] âŒ Failed to start run: ${(e as Error).message}`);
    iceeDb.close();
    process.exit(1);
  }

  console.log(`[ICEE] Run ID: ${runId}`);

  // ç­‰å¾… Run å®Œæˆ (è½®è¯¢æ´»è·ƒçŠ¶æ€)
  while (runtime.getActiveRunIds().includes(runId)) {
    await new Promise(r => setTimeout(r, 200));
  }

  const elapsed = Date.now() - startTime;
  console.log(`[ICEE] Total wall time: ${elapsed}ms`);

  iceeDb.close();
}
